{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup code for Google Colab\n",
    "USE_COLAB = False\n",
    "GOOGLE_DRIVE_PATH = ''\n",
    "if USE_COLAB:\n",
    "    print(\"Using Colab!\")\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    import os\n",
    "    GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'EECS545/SVM-Variations'\n",
    "    GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n",
    "    print(os.listdir(GOOGLE_DRIVE_PATH))\n",
    "\n",
    "    import sys\n",
    "    sys.path.append(GOOGLE_DRIVE_PATH)\n",
    "\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "    import torchvision\n",
    "    import statistics\n",
    "    import random\n",
    "    import time\n",
    "    import math\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "    import copy\n",
    "    import shutil\n",
    "    import os\n",
    "    import json\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "\n",
    "    !pip3 install -q idx2numpy\n",
    "\n",
    "    if torch.cuda.is_available:\n",
    "      print('Good to go!')\n",
    "    else:\n",
    "      print('Please set GPU via Edit -> Notebook Settings.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import SVMClass\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "############\n",
    "# load and plot data\n",
    "############\n",
    "if USE_COLAB:\n",
    "    nuclear = sio.loadmat(os.path.join(GOOGLE_DRIVE_PATH,'Data/nuclear.mat'))\n",
    "else:\n",
    "    nuclear = sio.loadmat('Data/nuclear.mat')\n",
    "\n",
    "x = torch.tensor(nuclear['x'], dtype = torch.float32, device = 'cuda')\n",
    "y = torch.tensor(nuclear['y'], dtype = torch.long, device = 'cuda')\n",
    "\n",
    "N = x.shape[1]\n",
    "\n",
    "## reshape data\n",
    "x = x.t()               # x \\in (N,D)\n",
    "y = y.reshape(N)        # y \\in (N,)\n",
    "\n",
    "# plot the data:\n",
    "negInd = y == -1\n",
    "posInd = y == 1\n",
    "plt.scatter(x.cpu()[negInd, 0], x.cpu()[negInd, 1], color='b')\n",
    "plt.scatter(x.cpu()[posInd, 0], x.cpu()[posInd, 1], color='r')\n",
    "plt.figure(1)\n",
    "plt.show()\n",
    "\n",
    "# change the label into {0,1}\n",
    "# y = (y+1)//2\n",
    "\n",
    "# Preprocess: append 1s at the end of data vectors\n",
    "ones_x = torch.ones((N,1), dtype = torch.float32, device = 'cuda')\n",
    "x_with_ones = torch.cat((x,ones_x),axis=1)\n",
    "x = x_with_ones\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verifying with EECS545 HW3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# get accuracy of sk lib svm implementation and our accuracy\n",
    "#########################\n",
    "from LinearSVM import *\n",
    "\n",
    "N = x.shape[0]\n",
    "indices = torch.randperm(N)\n",
    "train_N = N # 3 quarters of data is training. \n",
    "x_train = x[indices[0:train_N]]\n",
    "y_train = y[indices[0:train_N]]\n",
    "x_test = x[indices[train_N:]]\n",
    "y_test = y[indices[train_N:]]\n",
    "\n",
    "apply_sklearn_svm(x_train, y_train, x_test, y_test, max_iters = 1000)\n",
    "\n",
    "loss_history, LSVM = apply_LSVM(x_train, y_train, x_test, y_test, max_iters = 1000)\n",
    "\n",
    "\n",
    "\n",
    "##############################\n",
    "# plot our classifier line and Loss\n",
    "#############################\n",
    "W = LSVM.W[:]\n",
    "\n",
    "w1 = W[0].cpu()\n",
    "w2 = W[1].cpu()\n",
    "b = W[2].cpu()\n",
    "\n",
    "x0_vals = torch.tensor(np.linspace(0, 8, 8)).reshape(1,-1)\n",
    "y_vals = (-b - w1*x0_vals) / w2\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(x0_vals[0,:], y_vals[0,:], color='black', label='Learned line')\n",
    "plt.title('data')\n",
    "# plt.show()\n",
    "\n",
    "negInd = y == -1\n",
    "posInd = y == 1\n",
    "plt.scatter(x.cpu()[negInd, 0], x.cpu()[negInd, 1], color='b')\n",
    "plt.scatter(x.cpu()[posInd, 0], x.cpu()[posInd, 1], color='r')\n",
    "plt.figure(1)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(loss_history.cpu().detach().numpy())\n",
    "plt.title('Objective function J')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for hyperparameters that yield max accuracy\n",
    "model = LinearSVM()\n",
    "learning_rates = [1e-3, 1e-2, 5e-2, 1e-1, 5e-1, 1, 2]\n",
    "regs = [1e-4, 1e-3, 5e-3, 1e-2, 1e-1]\n",
    "folds = 10\n",
    "\n",
    "search_for_hyperparams(model, x_train, y_train, folds, learning_rates, regs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mnist Test Code\n",
    "from LinearSVM import *\n",
    "import Mnist_loader as mnist\n",
    "x_train, y_train, x_test, y_test = mnist.load_odd_even_Mnist()\n",
    "x_train, x_test, mu, std = mnist.preprocess_Mnist(x_train, x_test)\n",
    "apply_LSVM(x_train, y_train, x_test, y_test, max_iters = 1000)\n",
    "apply_sklearn_svm(x_train, y_train, x_test, y_test, max_iters = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVMGuide1 Test Code\n",
    "USE_COLAB = False\n",
    "GOOGLE_DRIVE_PATH = ''\n",
    "from LinearSVM import *\n",
    "from SVMGuide_loader import load_SVMGuide1\n",
    "x_train, y_train, x_test, y_test, mu, std = load_SVMGuide1(USE_COLAB, GOOGLE_DRIVE_PATH)\n",
    "apply_LSVM(x_train, y_train, x_test, y_test, max_iters = 1000)\n",
    "apply_sklearn_svm(x_train, y_train, x_test, y_test, max_iters = 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using KDD Dataset Test Code:\n",
    "# Download dataset from our google drive first. https://drive.google.com/drive/u/3/folders/1Alq22QmrDgMPhMfJVh-5WmgrKJmzTqCz\n",
    "from KDD_loader import kdd_load\n",
    "x_train, y_train, x_test, y_test = kdd_load()\n",
    "\n",
    "from LinearSVM import *\n",
    "from Evaluate_models import *\n",
    "LSVM = LinearSVM() \n",
    "LSVM.__init__()\n",
    "time, acc = evaluate_model(LSVM, x_train, y_train, x_test, y_test)\n",
    "print(time, acc)\n",
    "# apply_sklearn_svm(x_train, y_train, x_test, y_test, max_iters = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "With Mnist odd/even dataset, we get:\nWith Mnist 3/8 dataset, we get:\nWith SVM_Guide1 dataset, we get:\nUsing LSVM: Time =  0.6432580947875977   acc =  tensor(0.9555, device='cuda:0')\nUsing CSVM: Time =  0.2188563346862793   acc =  tensor(0.9205, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Code to compare different models in time and accuracy:\n",
    "from LinearSVM import *\n",
    "from ClusterSVM import *\n",
    "from Evaluate_models import *\n",
    "    \n",
    "\n",
    "# define models:\n",
    "LSVM = LinearSVM()  \n",
    "# KSVM = KernelSVM()\n",
    "CSVM = ClusterSVM()\n",
    "\n",
    "# evaluate using Mnist:\n",
    "# LSVM_time_oe, LSVM_acc_oe, LSVM_time_38, LSVM_acc_38 = evaluate_using_mnist(LSVM)\n",
    "# KSVM_time_oe, KSVM_acc_oe, KSVM_time_38, KSVM_acc_38 = evaluate_using_mnist(KSVM)\n",
    "# CSVM_time_oe, CSVM_acc_oe, CSVM_time_38, CSVM_acc_38 = evaluate_using_mnist(CSVM)\n",
    "\n",
    "# evaluate using SVM_Guide1:\n",
    "LSVM_time_svmg, LSVM_acc_svmg = evaluate_using_SVM_Guide1(LSVM)\n",
    "# KSVM_time_svmg, KSVM_acc_svmg = evaluate_using_SVM_Guide1(KSVM)\n",
    "CSVM_time_svmg, CSVM_acc_svmg = evaluate_using_SVM_Guide1(CSVM)\n",
    "\n",
    "\n",
    "print(\"With Mnist odd/even dataset, we get:\")\n",
    "# print(\"Using LSVM: Time = \", LSVM_time_oe, \"  acc = \", LSVM_acc_oe)\n",
    "# print(\"Using KSVM: Time = \", KSVM_time_oe, \"  acc = \", KSVM_acc_oe)\n",
    "# print(\"Using CSVM: Time = \", CSVM_time_oe, \"  acc = \", CSVM_acc_oe)\n",
    "\n",
    "print(\"With Mnist 3/8 dataset, we get:\")\n",
    "# print(\"Using LSVM: Time = \", LSVM_time_38, \"  acc = \", LSVM_acc_38)\n",
    "# print(\"Using KSVM: Time = \", KSVM_time_38, \"  acc = \", KSVM_acc_38)\n",
    "# print(\"Using CSVM: Time = \", CSVM_time_38, \"  acc = \", CSVM_acc_38)\n",
    "\n",
    "print(\"With SVM_Guide1 dataset, we get:\")\n",
    "print(\"Using LSVM: Time = \", LSVM_time_svmg, \"  acc = \", LSVM_acc_svmg)\n",
    "# print(\"Using KSVM: Time = \", KSVM_time_svmg, \"  acc = \", KSVM_acc_svmg)\n",
    "print(\"Using CSVM: Time = \", CSVM_time_svmg, \"  acc = \", CSVM_acc_svmg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}